{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Form13\n",
    "This notebook described how to use Neo4j and SageMaker together.  In it you connect to a Neo4j instance, load data and compute an embedding.  You then load that data into AWS S3 for later consumptin by SageMaker.\n",
    "\n",
    "You're going to want to run it in Colab or another environment that allows outbound access on port 7687.  Note that AWS SageMaker Studio blocks outbound access on all ports except for 53, 80 and 443.  You can click the link below to open the notebook in Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<a href=\"https://colab.research.google.com/github/neo4j-partners/neo4j-sagemaker/blob/main/form13/embedding.ipynb\" target=\"_blank\">\n",
    "<img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "</a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdMFRbqGzSqF"
   },
   "source": [
    "## Deploy Neo4j\n",
    "You're going to need a Neo4j deployment to run this lab.  The easiest way to get that is via the [AWS Marketplace](https://aws.amazon.com/marketplace/seller-profile?id=23ec694a-d2af-4641-b4d3-b7201ab2f5f9).  Select \"Neo4j Enterprise Edition\" and deploy that.  Suggested parameters are:\n",
    "\n",
    "* Graph Database Version - 4.4.6\n",
    "* Install Graph Data Sceince - True\n",
    "* Graph Data Science License Key - None\n",
    "* Install Bloom - True\n",
    "* Bloom License Key - None\n",
    "* Password - Enter something here\n",
    "* Node Count - 1\n",
    "* Instance Type - t3.xlarge\n",
    "* Key Name - Pick a key you have\n",
    "* SSH CIDR - 0.0.0.0/0\n",
    "\n",
    "The Marketplace listing deploys an ASG.  When deployment is complete, you can get the IP address of your Neo4j node from that ASG.  You can view deployed ASGs [here](https://us-east-1.console.aws.amazon.com/ec2autoscaling)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdMFRbqGzSqF"
   },
   "source": [
    "## Using the Neo4j API\n",
    "Now that we have a Neo4j deployment, let's connect to Neo4j.  First off, install the Neo4j Graph Data Science package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install graphdatascience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you're going to need the connection string and credentials from the deployment you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P41l_P4zzSqF"
   },
   "outputs": [],
   "source": [
    "# Edit these variables!\n",
    "DB_URL = 'neo4j://ec2-3-91-14-235.compute-1.amazonaws.com:7687'\n",
    "DB_PASS = 'foo123'\n",
    "\n",
    "# You can leave this default\n",
    "DB_USER = 'neo4j'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lUkSvmozSqF"
   },
   "outputs": [],
   "source": [
    "from graphdatascience import GraphDataScience\n",
    "gds = GraphDataScience(DB_URL, auth=(DB_USER, DB_PASS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data into Neo4j\n",
    "Now that we've got our connection object, let's load the dataset into Neo4j.\n",
    "\n",
    "The dataset is pulled from the SEC's EDGAR database. These are public filings of something called Form 13. Asset managers with over $100m AUM are required to submit Form 13 quarterly. That's then made available to the public over http. The csvs linked above were pulled from EDGAR using some python scripts. If you're curious, they're all available [here](https://github.com/neo4j-partners/neo4j-sec-edgar-form13). We've filtered the data to only include filings over $10m in value.\n",
    "\n",
    "We're going to create constratints for our data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gds.run_cypher('CREATE CONSTRAINT IF NOT EXISTS ON (p:Company) ASSERT (p.cusip) IS NODE KEY;')\n",
    "display(result)\n",
    "\n",
    "result = gds.run_cypher('CREATE CONSTRAINT IF NOT EXISTS ON (p:Manager) ASSERT (p.filingManager) IS NODE KEY;')\n",
    "display(result)\n",
    "\n",
    "result = gds.run_cypher('CREATE CONSTRAINT IF NOT EXISTS ON (p:Holding) ASSERT (p.filingManager, p.cusip, p.reportCalendarOrQuarter) IS NODE KEY;')\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gds.run_cypher(\n",
    "    \"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM 'https://storage.googleapis.com/neo4j-datasets/form13/2021.csv' AS row\n",
    "        MERGE (c:Company {cusip:row.cusip})\n",
    "        ON CREATE SET\n",
    "            c.nameOfIssuer=row.nameOfIssuer\n",
    "    \"\"\"\n",
    ")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gds.run_cypher(\n",
    "    \"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM 'https://storage.googleapis.com/neo4j-datasets/form13/2021.csv' AS row\n",
    "        MERGE (m:Manager {filingManager:row.filingManager})\n",
    "    \"\"\"\n",
    ")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gds.run_cypher(\n",
    "    \"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM 'https://storage.googleapis.com/neo4j-datasets/form13/2021.csv' AS row\n",
    "        MERGE (h:Holding {filingManager:row.filingManager, cusip:row.cusip, reportCalendarOrQuarter:row.reportCalendarOrQuarter})\n",
    "        ON CREATE SET\n",
    "            h.value=row.value, \n",
    "            h.shares=row.shares,\n",
    "            h.target=row.target,\n",
    "            h.nameOfIssuer=row.nameOfIssuer\n",
    "    \"\"\"\n",
    ")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create relationships between those nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gds.run_cypher(\n",
    "    \"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM 'https://storage.googleapis.com/neo4j-datasets/form13/2021.csv' AS row\n",
    "        MATCH (m:Manager {filingManager:row.filingManager})\n",
    "        MATCH (h:Holding {filingManager:row.filingManager, cusip:row.cusip, reportCalendarOrQuarter:row.reportCalendarOrQuarter})\n",
    "        MERGE (m)-[r:OWNS]->(h)\n",
    "    \"\"\"\n",
    ")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gds.run_cypher(\n",
    "    \"\"\"\n",
    "        LOAD CSV WITH HEADERS FROM 'https://storage.googleapis.com/neo4j-datasets/form13/2021.csv' AS row\n",
    "        MATCH (h:Holding {filingManager:row.filingManager, cusip:row.cusip, reportCalendarOrQuarter:row.reportCalendarOrQuarter})\n",
    "        MATCH (c:Company {cusip:row.cusip})\n",
    "        MERGE (h)-[r:PARTOF]->(c)\n",
    "    \"\"\"\n",
    ")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtJy4eO_zSqF"
   },
   "source": [
    "# Graph Data Science\n",
    "Now we're going to use Neo4j Graph Data Science to create an in memory graph represtation of the data.  We'll enhance that represation with features we engineer using a graph embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gds.run_cypher(\n",
    "  \"\"\"\n",
    "    CALL gds.graph.project(\n",
    "      'mygraph',\n",
    "      ['Company', 'Manager', 'Holding'],\n",
    "      {\n",
    "          OWNS: {orientation: 'UNDIRECTED'},\n",
    "          PARTOF: {orientation: 'UNDIRECTED'}\n",
    "      }\n",
    "    )\n",
    "    YIELD\n",
    "      graphName AS graph,\n",
    "      relationshipProjection AS readProjection,\n",
    "      nodeCount AS nodes,\n",
    "      relationshipCount AS rels\n",
    "  \"\"\"\n",
    ")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, if you get an error saying the graph already exists, that's probably because you ran this code before. You can destroy it using this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gds.run_cypher(\n",
    "  \"\"\"\n",
    "    CALL gds.graph.drop('mygraph')\n",
    "  \"\"\"\n",
    ")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's list the details of the graph to make sure the projection was created as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gds.run_cypher(\n",
    "  \"\"\"\n",
    "    CALL gds.graph.list()\n",
    "  \"\"\"\n",
    ")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate an embedding from that graph. This is a new feature we can use in our predictions. We're using FastRP, which is a more full featured and higher performance of Node2Vec. You can learn more about that [here](https://neo4j.com/docs/graph-data-science/current/algorithms/fastrp/).\n",
    "\n",
    "There are a bunch of parameters we could adjust in this.  One of the most obvious is the embeddingDimension.  The documentation covers many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gds.run_cypher(\n",
    "  \"\"\"\n",
    "  CALL gds.fastRP.mutate('mygraph',{\n",
    "    embeddingDimension: 16,\n",
    "    randomSeed: 1,\n",
    "    mutateProperty:'embedding'\n",
    "  })\n",
    "  \"\"\"\n",
    ")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That creates an embedding for each node type.  However, we only want the embedding on the nodes of type holding.\n",
    "\n",
    "We're going to take the embedding from our projection and write it to the holding nodes in the underlying database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gds.run_cypher(\n",
    "  \"\"\"\n",
    "    CALL gds.graph.writeNodeProperties('mygraph', ['embedding'], ['Holding'])\n",
    "    YIELD writeMillis\n",
    "  \"\"\"\n",
    ")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = gds.run_cypher(\n",
    "  \"\"\"\n",
    "    MATCH (n:Holding) RETURN n\n",
    "  \"\"\"\n",
    ")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this query will take 2-3 minutes to run as it's grabbing nearly half a million nodes along with all their properties and our new embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([dict(record.items()) for record in result['n']])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the embedding row is an array. To make this dataset more consumable, we should flatten that out into multiple individual features: embedding_0, embedding_1, ... embedding_n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.DataFrame(df['embedding'].values.tolist()).add_prefix(\"embedding_\")\n",
    "merged = df.drop(columns=['embedding']).merge(embeddings, left_index=True, right_index=True)\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data formatted properly, let's split it into a training and a testing set and write those to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged\n",
    "\n",
    "df['split']=df['reportCalendarOrQuarter']\n",
    "df['split']=df['split'].replace(['03-31-2021', '06-30-2021', '09-30-2021'], ['TRAIN', 'VALIDATE', 'TEST'])\n",
    "\n",
    "df = df.drop(columns=['reportCalendarOrQuarter'])\n",
    "\n",
    "df.to_csv('embedding.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Azb1inEVAC7f"
   },
   "source": [
    "# Upload to Amazom S3\n",
    "Now let's create a bucket and upload our data set to it.  Then we'll be able to access the data in SageMaker in the next lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mRKBGEi3AC7f"
   },
   "outputs": [],
   "source": [
    "filename='embedding.csv'\n",
    "\n",
    "#to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto\n",
    "import boto.s3\n",
    "import sys\n",
    "from boto.s3.key import Key\n",
    "\n",
    "AWS_ACCESS_KEY_ID = ''\n",
    "AWS_SECRET_ACCESS_KEY = ''\n",
    "\n",
    "bucket_name = AWS_ACCESS_KEY_ID.lower() + '-dump'\n",
    "conn = boto.connect_s3(AWS_ACCESS_KEY_ID,\n",
    "        AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "\n",
    "bucket = conn.create_bucket(bucket_name,\n",
    "    location=boto.s3.connection.Location.DEFAULT)\n",
    "\n",
    "testfile = \"replace this with an actual filename\"\n",
    "print 'Uploading %s to Amazon S3 bucket %s' % \\\n",
    "   (testfile, bucket_name)\n",
    "\n",
    "def percent_cb(complete, total):\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "k = Key(bucket)\n",
    "k.key = 'my test file'\n",
    "k.set_contents_from_filename(testfile,\n",
    "    cb=percent_cb, num_cb=10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "embedding.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
